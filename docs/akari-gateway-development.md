# 阿卡林网关 (Akari's Gateway) 开发文档

> **项目名称**: Akari's Gateway (阿卡林网关)  
> **版本**: 1.0.0  
> **最后更新**: 2026-01-17  
> **目标受众**: AI 模型开发者、系统架构师

---

## 📋 目录

1. [项目概述](#项目概述)
2. [架构设计](#架构设计)
3. [核心概念](#核心概念)
4. [模块说明](#模块说明)
5. [开发指南](#开发指南)
6. [后端集成](#后端集成)
7. [路由策略](#路由策略)
8. [故障转移机制](#故障转移机制)
9. [容灾设计](#容灾设计)
10. [扩展开发](#扩展开发)
11. [配置管理](#配置管理)
12. [测试指南](#测试指南)
13. [部署说明](#部署说明)

---

## 项目概述

### 项目定位

阿卡林网关是一个**统一 API 网关系统**，用于聚合多个 AI 模型服务后端，提供统一的 API 入口、智能路由、故障转移和负载均衡功能。

### 核心价值

- **统一入口**: 将多个后端服务整合到单一 API 端点
- **智能路由**: 根据模型名称、任务类型自动选择最优后端
- **故障转移**: 主后端失败时自动切换到备用后端
- **灵活扩展**: 支持动态添加新的后端服务
- **格式兼容**: 支持 OpenAI、Anthropic、Gemini 等多种 API 格式

### 技术栈

- **框架**: FastAPI (Python 3.12+)
- **异步**: asyncio, httpx
- **日志**: 自定义日志系统
- **配置**: 环境变量 + 配置文件

---

## 架构设计

### 整体架构

```
┌─────────────────────────────────────────────────────────┐
│                  客户端 (Client)                         │
│         (Cursor, Claude Code, 自定义应用)                │
└───────┬───────────────────────────────┬─────────────────┘
        │                               │
        │ 通过网关（推荐）                │ 直接访问后端（容灾）
        │                               │
┌───────▼───────────────────────────────▼─────────────────┐
│           阿卡林网关 (Akari's Gateway)                   │
│  ┌──────────────────────────────────────────────────┐  │
│  │  请求路由层 (Request Router)                      │  │
│  │  - 请求解析与规范化                                │  │
│  │  - 模型名称识别与映射                              │  │
│  │  - 路由策略决策                                    │  │
│  └──────────────┬───────────────────────────────────┘  │
│                 │                                       │
│  ┌──────────────▼───────────────────────────────────┐  │
│  │  后端管理层 (Backend Manager)                      │  │
│  │  - 后端健康检查                                    │  │
│  │  - 故障转移逻辑                                    │  │
│  │  - 负载均衡                                        │  │
│  └──────────────┬───────────────────────────────────┘  │
│                 │                                       │
│  ┌──────────────▼───────────────────────────────────┐  │
│  │  代理层 (Proxy Layer)                              │  │
│  │  - HTTP 请求转发                                   │  │
│  │  - 流式响应处理                                    │  │
│  │  - 错误处理与重试                                  │  │
│  └───────────────────────────────────────────────────┘  │
└────────────────────┬────────────────────────────────────┘
                     │
        ┌────────────┼────────────┬────────────┐
        │            │            │            │
┌───────▼───┐ ┌─────▼─────┐ ┌───▼──────┐ ┌───▼──────────┐
│ gcli2api  │ │ Copilot   │ │ Kiro     │ │ Anthropic    │
│ (本地)    │ │ (本地)    │ │ Gateway  │ │ Online       │
│ :7861     │ │ :8141     │ │ :9046    │ │ (在线)       │
│           │ │           │ │          │ │              │
│ 独立端点: │ │ 独立端点: │ │ 独立端点:│ │ 独立端点:    │
│ /v1       │ │ /v1       │ │ /v1      │ │ /v1          │
│ /antigravity/v1│        │ │          │ │              │
└───────────┘ └───────────┘ └──────────┘ └──────────────┘
```

### 容灾架构设计

**核心原则：网关是可选增强层，不是必需层**

#### 架构层次

1. **后端服务层（必需）**
   - 每个后端服务（gcli2api、Copilot 等）都是**完全独立**的服务
   - 每个后端都有自己的 API 端点，可以直接访问
   - 后端服务不依赖网关，可以独立运行和提供服务

2. **网关层（可选增强）**
   - 网关提供统一入口和增强功能（工具转换、智能路由等）
   - 网关故障不影响后端服务的正常运行
   - 用户可以在网关和后端之间自由切换

#### 容灾场景

**场景 1: 网关服务完全挂掉**

```
客户端 → [网关不可用] → 直接访问后端
         ↓
    gcli2api: http://127.0.0.1:7861/v1
    Copilot:  http://127.0.0.1:8141/v1
    Kiro:     http://127.0.0.1:9046/v1
```

**影响**:
- ✅ 后端服务继续正常运行
- ✅ 用户可以直接访问后端端点
- ❌ 失去网关的增强功能（工具转换、智能路由等）
- ❌ 需要手动切换端点配置

**场景 2: 网关部分功能故障**

```
客户端 → 网关（部分功能不可用）→ 降级到后端
```

**影响**:
- ✅ 基本功能继续工作
- ⚠️ 增强功能降级（如工具转换失败，使用后端原生格式）

**场景 3: 后端服务故障**

```
客户端 → 网关 → [后端A不可用] → 自动切换到后端B
```

**影响**:
- ✅ 网关自动故障转移
- ✅ 用户无感知切换

### 数据流

1. **请求接收**: 客户端发送请求到网关统一入口
2. **请求解析**: 网关解析请求，提取模型名称、消息内容等
3. **路由决策**: 根据模型名称和路由策略选择目标后端
4. **后端调用**: 代理请求到选定的后端服务
5. **响应处理**: 处理后端响应，进行格式转换（如需要）
6. **响应返回**: 将响应返回给客户端

### 关键设计原则

- **单一职责**: 每个模块只负责一个明确的功能
- **松耦合**: 后端服务通过 HTTP 接口集成，不直接依赖内部实现
- **可扩展性**: 新后端可以通过配置和代码扩展轻松添加
- **容错性**: 多层故障转移机制，确保服务可用性
- **容灾优先**: 网关是可选增强层，后端服务必须能独立运行
- **降级友好**: 网关故障时，用户可以直接访问后端端点，使用基本功能

---

## 核心概念

### 后端 (Backend)

后端是指提供 AI 模型服务的独立服务实例。每个后端具有以下属性：

- **标识符 (key)**: 唯一标识后端的字符串，如 `antigravity`、`copilot`
- **名称 (name)**: 人类可读的后端名称
- **基础 URL (base_url)**: 后端服务的 HTTP 端点
- **优先级 (priority)**: 数字越小优先级越高，用于故障转移顺序
- **超时配置**: 普通请求和流式请求的超时时间
- **重试配置**: 最大重试次数和重试策略
- **启用状态**: 是否启用该后端

### 路由策略 (Routing Strategy)

路由策略决定请求应该发送到哪个后端。当前支持：

- **模型名称匹配**: 根据模型名称精确或模糊匹配
- **优先级排序**: 按后端优先级顺序尝试
- **配置路由**: 通过环境变量配置特定模型的路由目标

### 故障转移 (Failover)

当主后端失败时，自动切换到备用后端的过程。故障转移遵循以下规则：

1. 按优先级顺序尝试后端
2. 如果指定了目标后端，优先尝试该后端
3. 如果目标后端失败，按优先级顺序尝试其他后端
4. 所有后端都失败时返回错误

### 请求规范化 (Request Normalization)

将不同客户端发送的请求格式转换为标准 OpenAI 格式的过程。处理包括：

- 消息格式转换（Augment、Cursor 等特殊格式）
- 工具定义规范化
- 模型名称清理和映射
- 参数验证和补全

---

## 模块说明

### 1. 路由模块 (Router Module)

**位置**: `src/gateway/router.py`

**职责**:
- 定义 FastAPI 路由端点
- 处理 HTTP 请求和响应
- 调用路由决策逻辑

**主要端点**:
- `POST /gateway/v1/chat/completions`: OpenAI 格式聊天完成
- `POST /gateway/v1/messages`: Anthropic Messages API 格式
- `GET /gateway/v1/models`: 获取所有后端支持的模型列表

### 2. 后端管理模块 (Backend Manager)

**位置**: `src/gateway/backends.py`

**职责**:
- 管理后端配置
- 提供后端查询接口
- 处理后端启用/禁用

**核心数据结构**:
- `BACKENDS`: 字典，存储所有后端配置
- 每个后端包含：name, base_url, priority, timeout, stream_timeout, max_retries, enabled

### 3. 路由决策模块 (Routing Module)

**位置**: `src/gateway/routing.py`

**职责**:
- 根据模型名称选择目标后端
- 实现路由策略逻辑
- 处理模型名称映射

**核心函数**:
- `get_backend_for_model(model: str) -> Optional[str]`: 根据模型名称获取目标后端
- `get_sorted_backends() -> List[Tuple[str, Dict]]`: 获取按优先级排序的后端列表

### 4. 代理模块 (Proxy Module)

**位置**: `src/gateway/proxy.py`

**职责**:
- 代理 HTTP 请求到后端服务
- 处理流式和非流式响应
- 实现重试机制
- 错误处理和转换

**核心函数**:
- `proxy_request_to_backend(...) -> Tuple[bool, Any]`: 代理请求到指定后端
- `route_request_with_fallback(...) -> Any`: 带故障转移的请求路由

### 5. 请求规范化模块 (Normalization Module)

**位置**: `src/gateway/normalization.py`

**职责**:
- 规范化请求体格式
- 处理不同客户端的特殊格式
- 工具定义转换
- 消息格式转换

**核心函数**:
- `normalize_request_body(body: Dict) -> Dict`: 规范化请求体
- `normalize_messages(messages: List) -> List`: 规范化消息列表
- `normalize_tools(tools: List) -> List`: 规范化工具定义

### 6. 格式转换模块 (Format Conversion)

**位置**: `src/gateway/formats/`

**职责**:
- OpenAI 格式 ↔ Anthropic 格式转换
- OpenAI 格式 ↔ Gemini 格式转换
- 工具调用格式转换
- 流式响应格式转换

---

## 开发指南

### 环境准备

1. **Python 版本**: 3.12 或更高
2. **依赖安装**: `pip install -r requirements.txt`
3. **环境变量**: 配置 `.env` 文件

### 项目结构

```
akari-gateway/
├── src/
│   ├── gateway/
│   │   ├── __init__.py
│   │   ├── router.py          # 主路由
│   │   ├── backends.py        # 后端管理
│   │   ├── routing.py         # 路由决策
│   │   ├── proxy.py           # 代理层
│   │   ├── normalization.py   # 请求规范化
│   │   └── formats/           # 格式转换
│   │       ├── openai.py
│   │       ├── anthropic.py
│   │       └── gemini.py
│   ├── backends/              # 后端实现
│   │   ├── __init__.py
│   │   ├── base.py            # 后端基类
│   │   ├── antigravity.py
│   │   ├── copilot.py
│   │   ├── kiro_gateway.py
│   │   └── anthropic_online.py
│   └── common/                # 共享工具
│       ├── auth.py
│       ├── http_client.py
│       ├── log.py
│       └── utils.py
├── tests/                     # 测试代码
├── docs/                      # 文档
├── requirements.txt
├── .env.example
└── main.py                    # 入口文件
```

### 代码规范

- **类型注解**: 所有函数必须包含类型注解
- **文档字符串**: 所有公共函数必须有 docstring
- **错误处理**: 使用明确的异常类型，提供有意义的错误信息
- **日志记录**: 使用统一的日志系统，包含适当的日志级别

### 开发流程

1. **创建功能分支**: `git checkout -b feature/your-feature`
2. **编写代码**: 遵循代码规范和架构设计
3. **编写测试**: 为新功能添加单元测试和集成测试
4. **更新文档**: 更新相关文档和注释
5. **代码审查**: 提交 PR 进行代码审查
6. **合并主分支**: 审查通过后合并到主分支

---

## 后端集成

### 添加新后端

#### 步骤 1: 创建后端实现类

在 `src/backends/` 目录下创建新的后端实现文件，继承 `BaseBackend` 类：

```python
from src.backends.base import BaseBackend

class YourBackend(BaseBackend):
    def __init__(self, config: dict):
        super().__init__(config)
        # 初始化特定配置
    
    async def health_check(self) -> bool:
        # 实现健康检查逻辑
        pass
    
    async def proxy_request(self, endpoint: str, method: str, 
                           headers: dict, body: dict, stream: bool) -> tuple:
        # 实现请求代理逻辑
        pass
```

#### 步骤 2: 注册后端

在 `src/gateway/backends.py` 的 `BACKENDS` 字典中添加配置：

```python
BACKENDS = {
    # ... 现有后端 ...
    "your-backend": {
        "name": "Your Backend",
        "base_url": "http://127.0.0.1:PORT/v1",
        "priority": 4,
        "timeout": 60.0,
        "stream_timeout": 300.0,
        "max_retries": 2,
        "enabled": True,
    }
}
```

#### 步骤 3: 配置路由策略

在 `src/gateway/routing.py` 的 `get_backend_for_model()` 函数中添加路由逻辑：

```python
def get_backend_for_model(model: str) -> Optional[str]:
    # ... 现有逻辑 ...
    
    # 添加你的后端路由逻辑
    if model.startswith("your-model-prefix"):
        return "your-backend"
    
    return None
```

#### 步骤 4: 环境变量配置（可选）

如果需要通过环境变量控制后端行为，在配置模块中添加：

```python
YOUR_BACKEND_ENABLED = os.getenv("YOUR_BACKEND_ENABLED", "true").lower() in ("true", "1", "yes")
YOUR_BACKEND_BASE_URL = os.getenv("YOUR_BACKEND_BASE_URL", "http://127.0.0.1:PORT/v1")
```

### 后端接口要求

新后端必须实现以下接口：

1. **健康检查**: 提供 `/health` 或 `/models` 端点用于健康检查
2. **API 兼容性**: 支持 OpenAI 兼容的 `/chat/completions` 端点
3. **流式支持**: 支持 `stream=true` 参数的流式响应
4. **错误格式**: 返回标准的 OpenAI 错误格式

---

## 路由策略

### 默认路由策略

网关按以下顺序选择后端：

1. **配置路由**: 检查是否有环境变量配置的特定模型路由
2. **模型匹配**: 根据模型名称前缀或完整匹配选择后端
3. **优先级排序**: 按后端优先级顺序尝试

### 路由优先级

数字越小优先级越高：

- `priority: 1`: 最高优先级（如 Antigravity）
- `priority: 2`: 次高优先级（如 Copilot）
- `priority: 3`: 中等优先级（如 Kiro Gateway）
- `priority: 4+`: 低优先级（备用后端）

### 模型名称映射

网关支持模型名称的灵活匹配：

- **精确匹配**: 完全相同的模型名称
- **前缀匹配**: 模型名称以特定前缀开头
- **模糊匹配**: 去除后缀（如 `-thinking`、`-preview`）后匹配

### 自定义路由规则

可以通过以下方式自定义路由：

1. **环境变量**: 设置 `KIRO_GATEWAY_MODELS` 等环境变量
2. **代码扩展**: 在 `routing.py` 中添加自定义路由逻辑
3. **配置文件**: 支持从配置文件加载路由规则（未来功能）

---

## 故障转移机制

### 故障检测

网关通过以下方式检测后端故障：

1. **HTTP 状态码**: 4xx、5xx 状态码视为故障
2. **超时**: 请求超时视为故障
3. **连接错误**: 网络连接错误视为故障

### 转移策略

1. **主后端优先**: 如果指定了目标后端，优先尝试该后端
2. **顺序尝试**: 主后端失败后，按优先级顺序尝试其他后端
3. **快速失败**: 如果所有后端都不可用，立即返回错误

### 重试机制

每个后端支持独立的重试配置：

- **最大重试次数**: `max_retries` 配置项
- **重试条件**: 仅对可重试错误（5xx、超时）进行重试
- **退避策略**: 指数退避（未来功能）

### 健康检查

网关可以定期检查后端健康状态（未来功能）：

- 定期发送健康检查请求
- 自动禁用不健康的后端
- 自动恢复健康的后端

---

## 容灾设计

### 设计理念

阿卡林网关采用**"可选增强层"**设计理念，确保：

1. **后端服务完全独立**: 每个后端服务都有自己的 API 端点，不依赖网关
2. **网关故障不影响后端**: 网关挂掉时，后端服务继续正常运行
3. **用户可手动切换**: 用户可以在网关和后端之间自由切换
4. **降级友好**: 即使失去网关的增强功能，后端也能提供基本功能

### 后端服务独立性

#### gcli2api 后端

**独立端点**:
- OpenAI 格式: `http://127.0.0.1:7861/v1/chat/completions`
- Antigravity OpenAI: `http://127.0.0.1:7861/antigravity/v1/chat/completions`
- Antigravity Anthropic: `http://127.0.0.1:7861/antigravity/v1/messages`
- Gemini 原生: `http://127.0.0.1:7861/v1/models/{model}:generateContent`

**功能完整性**:
- ✅ 支持 OpenAI 标准格式
- ✅ 支持 Anthropic Messages API 格式
- ✅ 支持 Gemini 原生格式
- ✅ 支持工具调用（tool_calls）
- ✅ 支持流式响应
- ⚠️ 部分 IDE 特殊格式转换需要网关增强

#### Copilot 后端

**独立端点**:
- OpenAI 格式: `http://127.0.0.1:8141/v1/chat/completions`

**功能完整性**:
- ✅ 支持 OpenAI 标准格式
- ✅ 支持 GPT 系列模型
- ✅ 支持流式响应
- ⚠️ 工具调用格式可能需要网关转换

#### 其他后端

每个后端服务都提供独立的 API 端点，可以直接访问，不依赖网关。

### 网关增强功能

网关提供的增强功能（非必需）：

1. **工具格式转换**
   - Cursor 特殊工具格式 → OpenAI 标准格式
   - Augment Code 工具定义 → OpenAI 工具格式
   - 工具调用索引修复

2. **请求规范化**
   - 处理不同客户端的非标准请求格式
   - 消息格式转换和清理
   - 参数验证和补全

3. **智能路由**
   - 根据模型名称自动选择最优后端
   - 跨后端故障转移
   - 负载均衡

4. **格式兼容**
   - 多格式 API 统一入口
   - 自动格式检测和转换

### 容灾方案

#### 方案 1: 网关故障 - 直接访问后端

**场景**: 网关服务完全不可用

**操作步骤**:
1. 检测网关不可用（连接超时、5xx 错误等）
2. 切换到后端服务的直接端点
3. 更新客户端配置中的 base_url

**配置示例**:
```yaml
# Claude Code 配置
# 网关模式（正常）
base_url: http://127.0.0.1:7861/gateway/v1

# 容灾模式（网关故障）
base_url: http://127.0.0.1:7861/v1  # 或 /antigravity/v1
```

**功能影响**:
- ✅ 基本聊天功能正常
- ✅ 工具调用功能正常（如果后端支持）
- ⚠️ 可能失去部分 IDE 特殊格式支持
- ⚠️ 需要手动选择后端（失去智能路由）

#### 方案 2: 网关部分功能故障 - 降级模式

**场景**: 网关运行但部分功能异常（如工具转换失败）

**处理策略**:
1. 网关检测到功能异常
2. 自动降级到后端原生格式
3. 跳过增强功能，直接转发请求

**实现方式**:
- 在代理层添加降级检测
- 工具转换失败时，使用后端原生工具格式
- 记录降级事件到日志

#### 方案 3: 后端服务故障 - 自动切换

**场景**: 某个后端服务不可用

**处理策略**:
1. 网关检测到后端故障
2. 自动切换到备用后端
3. 用户无感知

**实现方式**:
- 健康检查机制
- 故障转移逻辑
- 优先级排序

### 容灾检查清单

#### 后端服务检查

- [ ] 每个后端服务都有独立的 API 端点
- [ ] 后端服务不依赖网关启动
- [ ] 后端服务支持标准的 OpenAI/Anthropic 格式
- [ ] 后端服务支持基本的工具调用功能
- [ ] 后端服务有健康检查端点

#### 网关检查

- [ ] 网关故障不影响后端服务
- [ ] 网关提供降级模式
- [ ] 网关错误信息清晰，便于诊断
- [ ] 网关日志记录容灾事件

#### 客户端检查

- [ ] 客户端可以配置多个备用端点
- [ ] 客户端支持自动故障转移（可选）
- [ ] 客户端错误提示清晰，指导用户切换端点

### 容灾测试

#### 测试场景

1. **网关服务停止**
   - 停止网关服务
   - 验证后端服务继续运行
   - 验证可以直接访问后端端点
   - 验证基本功能正常

2. **网关进程崩溃**
   - 模拟网关进程崩溃
   - 验证后端服务不受影响
   - 验证可以手动切换到后端

3. **网关部分功能异常**
   - 模拟工具转换失败
   - 验证降级模式工作
   - 验证请求能正常转发

4. **后端服务故障**
   - 停止某个后端服务
   - 验证网关自动切换
   - 验证用户无感知

### 容灾最佳实践

1. **监控和告警**
   - 监控网关和后端服务的健康状态
   - 设置告警，及时发现问题
   - 记录容灾事件到日志

2. **文档和指南**
   - 提供容灾操作文档
   - 提供端点切换指南
   - 提供故障排查指南

3. **自动化恢复**
   - 实现网关自动重启机制
   - 实现后端服务自动恢复
   - 实现健康检查自动恢复

4. **用户通知**
   - 网关故障时通知用户
   - 提供备用端点信息
   - 提供故障恢复时间估计

---

## 扩展开发

### 添加新的 API 格式支持

1. 在 `src/gateway/formats/` 创建新的格式转换模块
2. 实现格式转换函数
3. 在路由模块中添加新的端点处理

### 添加新的路由策略

1. 在 `src/gateway/routing.py` 中扩展路由逻辑
2. 支持配置文件或数据库驱动的路由规则
3. 实现动态路由更新机制

### 添加监控和统计

1. 集成 Prometheus 或类似监控系统
2. 记录请求统计、错误率、延迟等指标
3. 提供监控仪表板

### 添加缓存机制

1. 实现响应缓存（适用于相同请求）
2. 实现模型列表缓存
3. 配置缓存过期策略

---

## 配置管理

### 环境变量

网关支持以下环境变量配置：

- `GATEWAY_PORT`: 网关服务端口（默认: 7861）
- `GATEWAY_HOST`: 网关服务主机（默认: 0.0.0.0）
- `KIRO_GATEWAY_ENABLED`: 是否启用 Kiro Gateway
- `KIRO_GATEWAY_BASE_URL`: Kiro Gateway 基础 URL
- `KIRO_GATEWAY_MODELS`: Kiro Gateway 路由的模型列表（逗号分隔）

### 配置文件

支持通过 TOML 或 YAML 配置文件管理后端配置（未来功能）。

### 动态配置

支持通过 API 端点动态更新配置（未来功能）：

- `POST /gateway/config/backend/{key}/toggle`: 启用/禁用后端
- `GET /gateway/config/backends`: 获取所有后端配置
- `PUT /gateway/config/backend/{key}`: 更新后端配置

---

## 测试指南

### 单元测试

为每个模块编写单元测试：

- 路由决策逻辑测试
- 请求规范化测试
- 格式转换测试
- 错误处理测试

### 集成测试

测试完整的请求-响应流程：

- 端到端请求测试
- 故障转移测试
- 多后端切换测试

### 性能测试

- 并发请求测试
- 延迟测试
- 吞吐量测试

### 测试工具

- **pytest**: 单元测试和集成测试框架
- **httpx**: 异步 HTTP 客户端，用于测试
- **pytest-asyncio**: 异步测试支持

---

## 部署说明

### 本地开发

```bash
# 安装依赖
pip install -r requirements.txt

# 配置环境变量
cp .env.example .env
# 编辑 .env 文件

# 启动服务
python main.py
```

### Docker 部署

```bash
# 构建镜像
docker build -t akari-gateway:latest .

# 运行容器
docker run -d \
  --name akari-gateway \
  -p 7861:7861 \
  -e GATEWAY_PORT=7861 \
  akari-gateway:latest
```

### 生产部署

1. **使用进程管理器**: systemd、supervisor 或 PM2
2. **反向代理**: 使用 Nginx 或 Caddy 作为反向代理
3. **负载均衡**: 多实例部署时使用负载均衡器
4. **监控**: 集成监控和日志系统
5. **SSL/TLS**: 配置 HTTPS 证书

### 性能优化

- **连接池**: 配置 HTTP 客户端连接池大小
- **超时优化**: 根据实际延迟调整超时时间
- **并发控制**: 限制并发请求数量
- **缓存**: 启用响应缓存（如适用）

---

## 常见问题

### Q: 如何添加新的后端服务？

A: 参考 [后端集成](#后端集成) 章节，按照步骤创建后端实现类、注册配置、配置路由策略。

### Q: 如何自定义路由规则？

A: 修改 `src/gateway/routing.py` 中的 `get_backend_for_model()` 函数，添加自定义路由逻辑。

### Q: 如何处理后端返回的非标准格式？

A: 在代理模块中添加格式转换逻辑，将后端响应转换为标准格式。

### Q: 如何调试路由决策？

A: 启用 DEBUG 日志级别，查看日志中的路由决策信息。日志会显示模型名称、选定的后端、路由原因等。

### Q: 性能如何优化？

A: 
- 使用连接池复用 HTTP 连接
- 启用响应缓存（如适用）
- 调整超时时间避免不必要的等待
- 使用异步 I/O 提高并发性能

### Q: 网关挂了怎么办？

A: 网关是可选增强层，挂掉不影响后端服务。可以：
1. 直接访问后端端点（如 `http://127.0.0.1:7861/v1`）
2. 更新客户端配置中的 base_url
3. 基本功能继续正常工作，只是失去网关的增强功能

### Q: 后端服务是否依赖网关？

A: **完全不依赖**。每个后端服务都是独立的，有自己的 API 端点，可以直接访问。网关只是提供统一入口和增强功能。

### Q: 失去网关后，Claude Code 还能用吗？

A: **可以**。只要后端服务支持标准的 OpenAI 格式和工具调用，Claude Code 就能正常工作。只是可能失去一些 IDE 特殊格式的转换能力。

---

## 贡献指南

### 代码提交

1. 遵循代码规范和架构设计
2. 为新功能添加测试
3. 更新相关文档
4. 提交清晰的 commit 消息

### 问题报告

在 GitHub Issues 中报告问题时，请提供：

- 问题描述
- 复现步骤
- 预期行为
- 实际行为
- 环境信息（Python 版本、操作系统等）
- 相关日志

### 功能请求

在 GitHub Issues 中提出功能请求时，请说明：

- 功能描述
- 使用场景
- 预期效果
- 可能的实现方案

---

## 版本历史

### v1.0.0 (2026-01-17)

- 初始版本发布
- 支持多后端聚合
- 实现智能路由和故障转移
- 支持 OpenAI 和 Anthropic 格式

---

## 许可证

本项目采用 Cooperative Non-Commercial License (CNC-1.0)。

---

## 联系方式

- **项目维护者**: Akari
- **GitHub**: [项目地址]
- **问题反馈**: [GitHub Issues]

---

**文档最后更新**: 2026-01-17  
**文档版本**: 1.0.0
