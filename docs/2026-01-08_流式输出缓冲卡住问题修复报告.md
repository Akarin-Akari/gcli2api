# 流式输出缓冲卡住问题修复报告

**日期**: 2026-01-08
**修复人**: Claude Opus 4.5 (浮浮酱)
**影响文件**: `src/anthropic_streaming.py`

## 问题描述

用户反馈：gcli2api 在转发 Claude 模型给 Cursor 时，工具调用（如写文档）无法流式写入，导致看上去像是卡住了。实际上后台在一个字一个字地处理，但输出被"藏起来"看不到。当内容非常多时会一直等待，最终导致对话超时。

## 问题分析

### 根本原因

在 `anthropic_streaming.py` 的 `antigravity_sse_to_anthropic_sse` 函数中，存在一个流式输出缓冲机制：

1. **message_start 延迟发送**：`message_start` 事件只有在收到 `usageMetadata.promptTokenCount` 后才会发送（第 248-249 行）
2. **事件缓冲机制**：在 `message_start` 发送之前，所有事件都被 `enqueue` 到 `pending_output` 列表中（第 177-178 行）
3. **延迟 flush**：`pending_output` 中的事件只有在 `send_message_start` 被调用后才会通过 `flush_pending_ready` 发送出去（第 209 行）

### 问题场景

```
上游服务器响应流程：
1. 发送 functionCall（工具调用）
2. 发送更多内容...
3. 最后才发送 usageMetadata（或根本不发送）

当前代码行为：
1. 收到 functionCall → enqueue 到 pending_output（因为 message_start 还没发送）
2. 收到更多内容 → 继续 enqueue
3. 流结束 → 才发送 message_start 并 flush pending_output
4. 结果：所有事件被缓冲，直到流结束才一次性发送
```

### 代码位置

```python
# 第 247-251 行（修复前）
# 为保证 message_start 永远是首个事件：在拿到真实值之前，把所有事件暂存到 pending_output。
if state.has_input_tokens and not message_start_sent:
    send_message_start(ready_output, input_tokens=state.input_tokens)

for part in parts:
    # 如果 message_start 还没发送，所有事件都会被 enqueue
    # 导致流式输出被缓冲
```

## 解决方案

在收到第一个有效内容（`parts` 非空）时，如果 `message_start` 还没发送，就立即使用估算的 token 数发送 `message_start`。

### 修复代码

```python
# 第 247-258 行（修复后）
# 为保证 message_start 永远是首个事件：在拿到真实值之前，把所有事件暂存到 pending_output。
if state.has_input_tokens and not message_start_sent:
    send_message_start(ready_output, input_tokens=state.input_tokens)

# [FIX 2026-01-08] 提前发送 message_start 以避免流式输出被缓冲
# 问题：如果上游延迟发送 usageMetadata，所有事件都会被 enqueue 到 pending_output
# 导致流式输出看起来"卡住"，直到流结束才一次性发送
# 解决：在收到第一个有效内容时，如果 message_start 还没发送，就使用估算值发送
if parts and not message_start_sent:
    # 有有效内容到来，立即发送 message_start（使用估算的 token 数）
    send_message_start(ready_output, input_tokens=initial_input_tokens_int)

for part in parts:
```

### 修复逻辑

1. **保留原有逻辑**：如果收到了真实的 `usageMetadata.promptTokenCount`，优先使用真实值
2. **新增兜底逻辑**：如果有有效内容到来但 `message_start` 还没发送，立即使用估算值发送
3. **确保流式输出**：一旦 `message_start` 发送，后续事件会立即 yield 而不是被缓冲

## 修复效果

| 场景 | 修复前 | 修复后 |
|------|--------|--------|
| 工具调用流式输出 | 被缓冲，看起来卡住 | 立即流式输出 |
| 大量内容写入 | 等待超时 | 实时显示进度 |
| token 计数准确性 | 准确（但延迟） | 估算值（但实时） |

## 备份信息

- 备份文件: `src/anthropic_streaming.py.bak.20260108_084330`
- 补丁脚本: `src/patch_streaming_buffer.py`

## 测试建议

1. 使用 Cursor 调用 Claude 模型进行工具调用（如写文档）
2. 观察流式输出是否实时显示
3. 验证大量内容写入时不会超时

## 相关问题

此修复可能与以下问题相关：
- 孤儿工具问题（orphan tool_result）
- Thinking block 处理

这些问题在之前的修复中已经处理，本次修复专注于流式输出缓冲问题。
