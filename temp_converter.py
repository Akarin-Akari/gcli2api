from __future__ import annotations

import json
import os
import re
from typing import Any, Dict, List, Optional, Union

from log import log


DEFAULT_THINKING_BUDGET = 1024
DEFAULT_TEMPERATURE = 0.4


def _anthropic_debug_enabled() -> bool:
    return str(os.getenv("ANTHROPIC_DEBUG", "")).strip().lower() in {"1", "true", "yes", "on"}


def _is_non_whitespace_text(value: Any) -> bool:
    """
    åˆ¤æ–­æ–‡æœ¬æ˜¯å¦åŒ…å«"éç©ºç™½"å†…å®¹ã€‚

    è¯´æ˜ï¼šä¸‹æ¸¸ï¼ˆAntigravity/Claude å…¼å®¹å±‚ï¼‰ä¼šå¯¹çº¯ text å†…å®¹å—åšæ ¡éªŒï¼š
    - text ä¸èƒ½ä¸ºç©ºå­—ç¬¦ä¸²
    - text ä¸èƒ½ä»…ç”±ç©ºç™½å­—ç¬¦ï¼ˆç©ºæ ¼/æ¢è¡Œ/åˆ¶è¡¨ç­‰ï¼‰ç»„æˆ

    å› æ­¤è¿™é‡Œç»Ÿä¸€æŠŠä»…ç©ºç™½çš„ text part è¿‡æ»¤æ‰ï¼Œä»¥é¿å… 400ï¼š
    `messages: text content blocks must contain non-whitespace text`ã€‚
    """
    if value is None:
        return False
    try:
        return bool(str(value).strip())
    except Exception:
        return False


def _is_thinking_disabled(thinking_value: Any) -> bool:
    """åˆ¤æ–­ thinking æ˜¯å¦è¢«æ˜¾å¼ç¦ç”¨"""
    if thinking_value is None:
        return False
    if isinstance(thinking_value, bool):
        return not thinking_value
    if isinstance(thinking_value, dict):
        return thinking_value.get("type") == "disabled"
    return False


def _should_strip_thinking_blocks(payload: Dict[str, Any]) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥åœ¨è¯·æ±‚è½¬æ¢æ—¶æ¸…ç† thinking blocksã€‚
    æ¸…ç†æ¡ä»¶ï¼ˆæ»¡è¶³ä»»ä¸€å³æ¸…ç†ï¼‰ï¼š
    1. thinking è¢«æ˜¾å¼ç¦ç”¨ï¼ˆtype: disabled æˆ– thinking: falseï¼‰
    2. thinking=nullï¼ˆä¸ä¸‹å‘ thinkingConfigï¼Œä¸‹æ¸¸è§†ä¸ºç¦ç”¨ï¼‰
    3. æ²¡æœ‰ thinking å­—æ®µï¼ˆä¸ä¸‹å‘ thinkingConfigï¼Œä¸‹æ¸¸è§†ä¸ºç¦ç”¨ï¼‰
    4. thinking å¯ç”¨ä½†å†å²æ¶ˆæ¯ä¸æ»¡è¶³çº¦æŸï¼ˆä¸ä¸‹å‘ thinkingConfigï¼Œä¸‹æ¸¸è§†ä¸ºç¦ç”¨ï¼‰

    æ ¸å¿ƒåŸåˆ™ï¼šåªè¦ä¸ä¼šä¸‹å‘ thinkingConfigï¼Œå°±åº”è¯¥æ¸…ç† thinking blocksï¼Œ
    é¿å…ä¸‹æ¸¸æŠ¥é”™ "When thinking is disabled, an assistant message cannot contain thinking"
    """
    # æ²¡æœ‰ thinking å­—æ®µ â†’ ä¸ä¸‹å‘ thinkingConfig â†’ éœ€è¦æ¸…ç†
    if "thinking" not in payload:
        return True

    thinking_value = payload.get("thinking")

    # thinking=null â†’ ä¸ä¸‹å‘ thinkingConfig â†’ éœ€è¦æ¸…ç†
    if thinking_value is None:
        return True

    # thinking è¢«æ˜¾å¼ç¦ç”¨ â†’ éœ€è¦æ¸…ç†
    if _is_thinking_disabled(thinking_value):
        return True

    # thinking å¯ç”¨ï¼Œæ£€æŸ¥æ˜¯å¦ä¼šå®é™…ä¸‹å‘ thinkingConfig
    # å¦‚æœå†å²æ¶ˆæ¯ä¸æ»¡è¶³çº¦æŸï¼ŒthinkingConfig ä¸ä¼šè¢«ä¸‹å‘
    thinking_config = get_thinking_config(thinking_value)
    include_thoughts = bool(thinking_config.get("includeThoughts", False))

    if not include_thoughts:
        # includeThoughts=False â†’ éœ€è¦æ¸…ç†
        return True

    # æ£€æŸ¥æœ€åä¸€æ¡ assistant æ¶ˆæ¯çš„ç¬¬ä¸€ä¸ª block ç±»å‹
    messages = payload.get("messages") or []
    last_assistant_first_block_type = None
    for msg in reversed(messages):
        if not isinstance(msg, dict):
            continue
        if msg.get("role") != "assistant":
            continue
        content = msg.get("content")
        if not isinstance(content, list) or not content:
            continue
        first_block = content[0]
        if isinstance(first_block, dict):
            last_assistant_first_block_type = first_block.get("type")
        else:
            last_assistant_first_block_type = None
        break

    # å¦‚æœæœ€åä¸€æ¡ assistant æ¶ˆæ¯çš„ç¬¬ä¸€ä¸ª block ä¸æ˜¯ thinking/redacted_thinkingï¼Œ
    # åˆ™ thinkingConfig ä¸ä¼šè¢«ä¸‹å‘ â†’ éœ€è¦æ¸…ç†
    if last_assistant_first_block_type not in {None, "thinking", "redacted_thinking"}:
        return True

    # æ£€æŸ¥ budget æ˜¯å¦ä¼šå¯¼è‡´ thinkingConfig ä¸ä¸‹å‘
    max_tokens = payload.get("max_tokens")
    if isinstance(max_tokens, int):
        budget = thinking_config.get("thinkingBudget")
        if isinstance(budget, int) and budget >= max_tokens:
            adjusted_budget = max(0, max_tokens - 1)
            if adjusted_budget <= 0:
                # budget æ— æ³•è°ƒæ•´ â†’ thinkingConfig ä¸ä¸‹å‘ â†’ éœ€è¦æ¸…ç†
                return True

    # å…¶ä»–æƒ…å†µï¼šthinkingConfig ä¼šè¢«ä¸‹å‘ï¼Œä¸éœ€è¦æ¸…ç†
    return False


def _strip_thinking_blocks_from_messages(messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    ä»æ¶ˆæ¯åˆ—è¡¨ä¸­ç§»é™¤æ‰€æœ‰ thinking/redacted_thinking blocksã€‚
    å½“ thinking è¢«ç¦ç”¨æ—¶ï¼Œå†å²æ¶ˆæ¯ä¸­çš„ thinking blocks ä¼šå¯¼è‡´ 400 é”™è¯¯ï¼š
    "When thinking is disabled, an `assistant` message..."

    æ­¤å‡½æ•°ä¼šï¼š
    1. éå†æ‰€æœ‰æ¶ˆæ¯
    2. å¯¹äº assistant æ¶ˆæ¯ï¼Œç§»é™¤ content ä¸­çš„ thinking/redacted_thinking blocks
    3. ä¿ç•™å…¶ä»–æ‰€æœ‰å†…å®¹ï¼ˆtext, tool_use, tool_result ç­‰ï¼‰

    æ³¨æ„ï¼šthinking blocks åªæ˜¯æ¨¡å‹çš„å†…éƒ¨æ¨ç†è¿‡ç¨‹ï¼Œç§»é™¤å®ƒä»¬ä¸ä¼šå½±å“å¯¹è¯çš„æ ¸å¿ƒå†…å®¹ã€‚
    """
    if not messages:
        return messages

    cleaned_messages = []
    for msg in messages:
        if not isinstance(msg, dict):
            cleaned_messages.append(msg)
            continue

        role = msg.get("role")
        content = msg.get("content")

        # åªå¤„ç† assistant æ¶ˆæ¯çš„ content
        if role != "assistant" or not isinstance(content, list):
            cleaned_messages.append(msg)
            continue

        # è¿‡æ»¤æ‰ thinking å’Œ redacted_thinking blocks
        cleaned_content = []
        for item in content:
            if isinstance(item, dict):
                item_type = item.get("type")
                if item_type in ("thinking", "redacted_thinking"):
                    # è·³è¿‡ thinking blocks
                    continue
            cleaned_content.append(item)

        # å¦‚æœæ¸…ç†å content ä¸ºç©ºï¼Œæ·»åŠ ä¸€ä¸ªç©ºæ–‡æœ¬å—é¿å…æ ¼å¼é”™è¯¯
        if not cleaned_content:
            cleaned_content = [{"type": "text", "text": "..."}]

        # åˆ›å»ºæ–°çš„æ¶ˆæ¯å¯¹è±¡
        cleaned_msg = msg.copy()
        cleaned_msg["content"] = cleaned_content
        cleaned_messages.append(cleaned_msg)

    return cleaned_messages


def get_thinking_config(thinking: Optional[Union[bool, Dict[str, Any]]]) -> Dict[str, Any]:
    """
    æ ¹æ® Anthropic/Claude è¯·æ±‚çš„ thinking å‚æ•°ç”Ÿæˆä¸‹æ¸¸ thinkingConfigã€‚

    è¯¥é€»è¾‘ä»¥æ ¹ç›®å½• `converter.py` çš„è¯­ä¹‰ä¸ºå‡†ï¼š
    - thinking=Noneï¼šé»˜è®¤å¯ç”¨ includeThoughtsï¼Œå¹¶ä½¿ç”¨é»˜è®¤ budget
    - thinking=boolï¼šTrue å¯ç”¨ / False ç¦ç”¨
    - thinking=dictï¼š{'type':'enabled'|'disabled', 'budget_tokens': int}
    """
    if thinking is None:
        return {"includeThoughts": True, "thinkingBudget": DEFAULT_THINKING_BUDGET}

    if isinstance(thinking, bool):
        if thinking:
            return {"includeThoughts": True, "thinkingBudget": DEFAULT_THINKING_BUDGET}
        return {"includeThoughts": False}

    if isinstance(thinking, dict):
        thinking_type = thinking.get("type", "enabled")
        is_enabled = thinking_type == "enabled"
        if not is_enabled:
            return {"includeThoughts": False}

        budget = thinking.get("budget_tokens", DEFAULT_THINKING_BUDGET)
        return {"includeThoughts": True, "thinkingBudget": budget}

    return {"includeThoughts": True, "thinkingBudget": DEFAULT_THINKING_BUDGET}


def map_claude_model_to_gemini(claude_model: str) -> str:
    """
    å°† Claude æ¨¡å‹åæ˜ å°„ä¸ºä¸‹æ¸¸æ¨¡å‹åï¼ˆå«â€œæ”¯æŒåˆ—è¡¨é€ä¼ â€ä¸å›ºå®šæ˜ å°„ï¼‰ã€‚

    è¯¥é€»è¾‘ä»¥æ ¹ç›®å½• `converter.py` ä¸ºå‡†ã€‚
    """
    claude_model = str(claude_model or "").strip()
    if not claude_model:
        return "claude-sonnet-4-5"

    # claude-cli å¸¸è§çš„ç‰ˆæœ¬åŒ–æ¨¡å‹åï¼Œä¾‹å¦‚ï¼š
    # - claude-opus-4-5-20251101
    # - claude-haiku-4-5-20251001
    # è¿™ç±»åç§°ä¸åœ¨ converter.py çš„å›ºå®šæ˜ å°„ä¸­ï¼Œä¼šè½å…¥é»˜è®¤å€¼ï¼Œä»è€Œå¯¼è‡´â€œçœ‹èµ·æ¥åƒè¢«å¼ºåˆ¶ç”¨ sonnetâ€ã€‚
    # è¿™é‡Œåšä¸€æ¬¡è§„èŒƒåŒ–ï¼Œä½¿å…¶æ›´è´´è¿‘ç”¨æˆ·é¢„æœŸã€‚
    m = re.match(r"^(claude-(?:opus|sonnet|haiku)-4-5)-\d{8}$", claude_model)
    if m:
        claude_model = m.group(1)

    # å¯¹ claude 4.5 ç³»åˆ—åšæ›´åˆç†çš„è½åœ°æ˜ å°„ï¼ˆä¿æŒä¸‹æ¸¸å¯ç”¨æ€§ä¼˜å…ˆï¼‰
    if claude_model == "claude-opus-4-5":
        return "claude-opus-4-5-thinking"
    if claude_model == "claude-sonnet-4-5":
        return "claude-sonnet-4-5"
    if claude_model == "claude-haiku-4-5":
        return "gemini-2.5-flash"

    supported_models = {
        # Gemini ç³»åˆ—
        "gemini-2.5-flash",
        "gemini-2.5-flash-thinking",
        "gemini-2.5-flash-lite",
        "gemini-2.5-flash-image",
        "gemini-2.5-pro",
        "gemini-3-flash",
        "gemini-3-pro-low",
        "gemini-3-pro-high",
        "gemini-3-pro-image",
        # Claude ç³»åˆ—
        "claude-sonnet-4-5",
        "claude-sonnet-4-5-thinking",
        "claude-opus-4-5-thinking",
        # GPT ç³»åˆ—
        "gpt-oss-120b-medium",
        # å†…éƒ¨æµ‹è¯•æ¨¡å‹ï¼ˆé¢„ç•™ï¼‰
        "rev19-uic3-1p",
        "chat_20706",
        "chat_23310",
    }

    if claude_model in supported_models:
        return claude_model

    model_mapping = {
        "claude-sonnet-4.5": "claude-sonnet-4-5",
        "claude-3-5-sonnet-20241022": "claude-sonnet-4-5",
        "claude-3-5-sonnet-20240620": "claude-sonnet-4-5",
        "claude-opus-4": "gemini-3-pro-high",
        "claude-haiku-4": "claude-haiku-4.5",
        "claude-3-haiku-20240307": "gemini-2.5-flash",
    }

    return model_mapping.get(claude_model, "claude-sonnet-4-5")


def clean_json_schema(schema: Any) -> Any:
    """
    æ¸…ç† JSON Schemaï¼Œç§»é™¤ä¸‹æ¸¸ä¸æ”¯æŒçš„å­—æ®µï¼Œå¹¶æŠŠéªŒè¯è¦æ±‚è¿½åŠ åˆ° descriptionã€‚

    è¯¥é€»è¾‘ä»¥æ ¹ç›®å½• `converter.py` çš„è¯­ä¹‰ä¸ºå‡†ã€‚
    """
    if not isinstance(schema, dict):
        return schema

    # ä¸‹æ¸¸ï¼ˆAntigravity/Vertex/Geminiï¼‰å¯¹ tool parameters çš„ JSON Schema æ”¯æŒèŒƒå›´å¾ˆçª„ï¼Œ
    # ä¸€äº›æ ‡å‡†å­—æ®µä¼šç›´æ¥è§¦å‘ 400ï¼ˆä¾‹å¦‚ $ref / exclusiveMinimumï¼‰ã€‚
    #
    # è¿™é‡Œå‚è€ƒ `src/openai_transfer.py::_clean_schema_for_gemini` çš„åå•ï¼Œåšä¸€æ¬¡ç»Ÿä¸€å‰”é™¤ï¼Œ
    # ä»¥ä¿è¯ Anthropic tools -> ä¸‹æ¸¸ functionDeclarations çš„å…¼å®¹æ€§ã€‚
    unsupported_keys = {
        "$schema",
        "$id",
        "$ref",
        "$defs",
        "definitions",
        "title",
        "example",
        "examples",
        "readOnly",
        "writeOnly",
        "default",
        "exclusiveMaximum",
        "exclusiveMinimum",
        "oneOf",
        "anyOf",
        "allOf",
        "const",
        "additionalItems",
        "contains",
        "patternProperties",
        "dependencies",
        "propertyNames",
        "if",
        "then",
        "else",
        "contentEncoding",
        "contentMediaType",
    }

    validation_fields = {
        "minLength": "minLength",
        "maxLength": "maxLength",
        "minimum": "minimum",
        "maximum": "maximum",
        "minItems": "minItems",
        "maxItems": "maxItems",
    }
    fields_to_remove = {"additionalProperties"}

    validations: List[str] = []
    for field, label in validation_fields.items():
        if field in schema:
            validations.append(f"{label}: {schema[field]}")

    cleaned: Dict[str, Any] = {}
    for key, value in schema.items():
        if key in unsupported_keys or key in fields_to_remove or key in validation_fields:
            continue

        if key == "type" and isinstance(value, list):
            # Roo/Anthropic SDK å¸¸è§å†™æ³•ï¼štype: ["string", "null"]
            # ä¸‹æ¸¸ï¼ˆProto é£æ ¼ Schemaï¼‰é€šå¸¸è¦æ±‚ type ä¸ºå•å€¼å­—æ®µï¼Œå¹¶ä½¿ç”¨ nullable è¡¨è¾¾å¯ç©ºã€‚
            has_null = any(
                isinstance(t, str) and t.strip() and t.strip().lower() == "null" for t in value
            )
            non_null_types = [
                t.strip()
                for t in value
                if isinstance(t, str) and t.strip() and t.strip().lower() != "null"
            ]

            cleaned[key] = non_null_types[0] if non_null_types else "string"
            if has_null:
                cleaned["nullable"] = True
            continue

        if key == "description" and validations:
            cleaned[key] = f"{value} ({', '.join(validations)})"
        elif key == "properties":
            # ç‰¹æ®Šå¤„ç† propertiesï¼šç¡®ä¿æ¯ä¸ªå±æ€§çš„å€¼éƒ½æ˜¯å®Œæ•´çš„ Schema å¯¹è±¡
            if isinstance(value, dict):
                cleaned_properties: Dict[str, Any] = {}
                for prop_name, prop_schema in value.items():
                    if isinstance(prop_schema, dict):
                        # é€’å½’æ¸…ç†å±æ€§ Schema
                        cleaned_prop = clean_json_schema(prop_schema)
                        # å¦‚æœå±æ€§ç±»å‹æ˜¯ objectï¼Œç¡®ä¿å®ƒæ˜¯ä¸€ä¸ªå®Œæ•´çš„ Schema å¯¹è±¡
                        if cleaned_prop.get("type") == "object":
                            # ç¡®ä¿ object ç±»å‹æœ‰å®Œæ•´çš„ Schema ç»“æ„
                            if "properties" not in cleaned_prop:
                                cleaned_prop["properties"] = {}
                            # ç¡®ä¿æœ‰ type å­—æ®µ
                            if "type" not in cleaned_prop:
                                cleaned_prop["type"] = "object"
                        cleaned_properties[prop_name] = cleaned_prop
                    elif isinstance(prop_schema, str) and prop_schema == "object":
                        # å¦‚æœå€¼æ˜¯å­—ç¬¦ä¸² "object"ï¼Œè½¬æ¢ä¸ºå®Œæ•´çš„ Schema å¯¹è±¡
                        cleaned_properties[prop_name] = {"type": "object", "properties": {}}
                    else:
                        # å…¶ä»–æƒ…å†µç›´æ¥ä½¿ç”¨åŸå€¼ï¼ˆä½†åº”è¯¥ä¸ä¼šå‘ç”Ÿï¼‰
                        cleaned_properties[prop_name] = prop_schema
                cleaned[key] = cleaned_properties
            else:
                cleaned[key] = value
        elif isinstance(value, dict):
            cleaned[key] = clean_json_schema(value)
        elif isinstance(value, list):
            cleaned[key] = [clean_json_schema(item) if isinstance(item, dict) else item for item in value]
        else:
            cleaned[key] = value

    if validations and "description" not in cleaned:
        cleaned["description"] = f"Validation: {', '.join(validations)}"

    # ä¸ `src/openai_transfer.py::_clean_schema_for_gemini` ä¿æŒä¸€è‡´ï¼š
    # å¦‚æœæœ‰ properties ä½†æ²¡æœ‰æ˜¾å¼ typeï¼Œåˆ™è¡¥é½ä¸º objectï¼Œé¿å…ä¸‹æ¸¸æ ¡éªŒå¤±è´¥ã€‚
    if "properties" in cleaned and "type" not in cleaned:
        cleaned["type"] = "object"

    # ä¿® Cursor å…¼å®¹æ€§ï¼šç¡®ä¿ input_schema å§‹ç»ˆæœ‰ type å­—æ®µ
    # é”™è¯¯ "tools.0.custom.input_schema.type: Field required" è¡¨æ˜ä¸‹æ¸¸è¦æ±‚ type å¿…å¡«
    # å¦‚æœ cleaned éç©ºä½†æ²¡æœ‰ typeï¼Œé»˜è®¤è¡¥é½ä¸º "object"
    if cleaned and "type" not in cleaned:
        cleaned["type"] = "object"

    return cleaned


def convert_tools(anthropic_tools: Optional[List[Dict[str, Any]]]) -> Optional[List[Dict[str, Any]]]:
    """
    å°† Anthropic tools[] è½¬æ¢ä¸ºä¸‹æ¸¸ toolsï¼ˆfunctionDeclarationsï¼‰ç»“æ„ã€‚
    """
    if not anthropic_tools:
        return None

    gemini_tools: List[Dict[str, Any]] = []
    for tool in anthropic_tools:
        name = tool.get("name")
        if not name:
            continue
        description = tool.get("description", "")
        input_schema = tool.get("input_schema", {}) or {}
        parameters = clean_json_schema(input_schema)

        gemini_tools.append(
            {
                "functionDeclarations": [
                    {
                        "name": name,
                        "description": description,
                        "parameters": parameters,
                    }
                ]
            }
        )

    return gemini_tools or None


def _extract_tool_result_output(content: Any) -> str:
    """
    ä» tool_result.content ä¸­æå–è¾“å‡ºå­—ç¬¦ä¸²ï¼ˆæŒ‰ converter.py çš„æœ€å°è¯­ä¹‰ï¼‰ã€‚
    """
    if isinstance(content, list):
        if not content:
            return ""
        first = content[0]
        if isinstance(first, dict) and first.get("type") == "text":
            return str(first.get("text", ""))
        return str(first)
    if content is None:
        return ""
    return str(content)


def convert_messages_to_contents(messages: List[Dict[str, Any]], *, include_thinking: bool = True) -> List[Dict[str, Any]]:
    """
    å°† Anthropic messages[] è½¬æ¢ä¸ºä¸‹æ¸¸ contents[]ï¼ˆrole: user/model, parts: []ï¼‰ã€‚

    Args:
        messages: Anthropic æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
        include_thinking: æ˜¯å¦åŒ…å« thinking å—ï¼ˆå½“è¯·æ±‚æœªå¯ç”¨ thinking æ—¶åº”è®¾ä¸º Falseï¼‰
    """
    contents: List[Dict[str, Any]] = []

    # ç¬¬ä¸€éï¼šå»ºç«‹ tool_use_id -> name çš„æ˜ å°„
    # Anthropic çš„ tool_result æ¶ˆæ¯ä¸åŒ…å« name å­—æ®µï¼Œä½† Gemini çš„ functionResponse éœ€è¦ name
    tool_use_id_to_name: Dict[str, str] = {}
    for msg in messages:
        raw_content = msg.get("content", "")
        if isinstance(raw_content, list):
            for item in raw_content:
                if isinstance(item, dict) and item.get("type") == "tool_use":
                    tool_id = item.get("id")
                    tool_name = item.get("name")
                    if tool_id and tool_name:
                        tool_use_id_to_name[str(tool_id)] = str(tool_name)

    for msg in messages:
        role = msg.get("role", "user")
        gemini_role = "model" if role == "assistant" else "user"
        raw_content = msg.get("content", "")

        parts: List[Dict[str, Any]] = []
        if isinstance(raw_content, str):
            if _is_non_whitespace_text(raw_content):
                parts = [{"text": str(raw_content)}]
        elif isinstance(raw_content, list):
            for item in raw_content:
                if not isinstance(item, dict):
                    if _is_non_whitespace_text(item):
                        parts.append({"text": str(item)})
                    continue

                item_type = item.get("type")
                if item_type == "thinking":
                    # å¦‚æœè¯·æ±‚æœªå¯ç”¨ thinkingï¼Œåˆ™è·³è¿‡å†å² thinking å—
                    if not include_thinking:
                        continue

                    # Anthropic çš„å†å² thinking block åœ¨å›æ”¾æ—¶é€šå¸¸è¦æ±‚æºå¸¦ signatureï¼›
                    # è‹¥ç¼ºå¤± signatureï¼Œä¸‹æ¸¸å¯èƒ½ä¼šæŠ¥ "thinking.signature: Field required"ã€‚
                    # ä¸ºä¿è¯å…¼å®¹æ€§ï¼Œè¿™é‡Œé€‰æ‹©ä¸¢å¼ƒæ—  signature çš„ thinking blockã€‚
                    signature = item.get("signature")
                    if not signature:
                        continue

                    thinking_text = item.get("thinking", "")
                    if thinking_text is None:
                        thinking_text = ""
                    part: Dict[str, Any] = {
                        "text": str(thinking_text),
                        "thought": True,
                        "thoughtSignature": signature,
                    }
                    parts.append(part)
                elif item_type == "redacted_thinking":
                    # å¦‚æœè¯·æ±‚æœªå¯ç”¨ thinkingï¼Œåˆ™è·³è¿‡å†å² redacted_thinking å—
                    if not include_thinking:
                        continue

                    signature = item.get("signature")
                    if not signature:
                        continue

                    # redacted_thinking çš„å…·ä½“å­—æ®µåœ¨ä¸åŒå®¢æˆ·ç«¯å¯èƒ½ä¸åŒï¼Œè¿™é‡Œå°½é‡å…¼å®¹ data/thinkingã€‚
                    thinking_text = item.get("thinking")
                    if thinking_text is None:
                        thinking_text = item.get("data", "")
                    parts.append(
                        {
                            "text": str(thinking_text or ""),
                            "thought": True,
                            "thoughtSignature": signature,
                        }
                    )
                elif item_type == "text":
                    text = item.get("text", "")
                    if _is_non_whitespace_text(text):
                        parts.append({"text": str(text)})
                elif item_type == "image":
                    source = item.get("source", {}) or {}
                    if source.get("type") == "base64":
                        parts.append(
                            {
                                "inlineData": {
                                    "mimeType": source.get("media_type", "image/png"),
                                    "data": source.get("data", ""),
                                }
                            }
                        )
                elif item_type == "tool_use":
                    # Gemini 3 è¦æ±‚ functionCall å¿…é¡»åŒ…å« thoughtSignature
                    # å‚è€ƒ: https://ai.google.dev/gemini-api/docs/thought-signatures
                    # å¦‚æœæ²¡æœ‰ signatureï¼Œä½¿ç”¨ dummy å€¼ç»•è¿‡éªŒè¯
                    fc_part: Dict[str, Any] = {
                        "functionCall": {
                            "id": item.get("id"),
                            "name": item.get("name"),
                            "args": item.get("input", {}) or {},
                        },
                        # æ·»åŠ  dummy thoughtSignature ä»¥æ»¡è¶³ Gemini 3 çš„è¦æ±‚ï¼ˆåœ¨ part çº§åˆ«ï¼‰
                        "thoughtSignature": "skip_thought_signature_validator",
                    }
                    parts.append(fc_part)
                elif item_type == "tool_result":
                    output = _extract_tool_result_output(item.get("content"))
                    tool_use_id = item.get("tool_use_id")
                    # ä»æ˜ å°„ä¸­è·å– nameï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™ä½¿ç”¨ tool_use_id ä½œä¸ºå…œåº•
                    # Gemini è¦æ±‚ functionResponse.name å¿…é¡»éç©º
                    tool_name = tool_use_id_to_name.get(str(tool_use_id), "") if tool_use_id else ""
                    if not tool_name:
                        # å…œåº•ï¼šä½¿ç”¨ tool_use_id ä½œä¸º nameï¼Œé¿å…ç©ºå€¼å¯¼è‡´ 400 é”™è¯¯
                        tool_name = str(tool_use_id) if tool_use_id else "unknown_tool"
                    parts.append(
                        {
                            "functionResponse": {
                                "id": tool_use_id,
                                "name": tool_name,
                                "response": {"output": output},
                            }
                        }
                    )
                else:
                    parts.append({"text": json.dumps(item, ensure_ascii=False)})
        else:
            if _is_non_whitespace_text(raw_content):
                parts = [{"text": str(raw_content)}]

        # é¿å…äº§ç”Ÿç©º partsï¼ˆä¸‹æ¸¸å¯èƒ½ä¼šæŠ¥é”™ï¼‰ï¼Œç›´æ¥è·³è¿‡è¯¥æ¡ç©ºæ¶ˆæ¯ã€‚
        if not parts:
            continue

        contents.append({"role": gemini_role, "parts": parts})

    return contents


def reorganize_tool_messages(contents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    é‡æ–°ç»„ç»‡æ¶ˆæ¯ï¼Œå°½é‡æ»¡è¶³ Anthropic çš„ tool_use/tool_result çº¦æŸï¼š
    - æ¯ä¸ª tool_useï¼ˆä¸‹æ¸¸è¡¨ç°ä¸º functionCallï¼‰å¿…é¡»ç´§è·Ÿä¸€ä¸ªå¯¹åº”çš„ tool_resultï¼ˆä¸‹æ¸¸è¡¨ç°ä¸º functionResponseï¼‰

    è¯¥é€»è¾‘â€œå¯¹é½/ç§»æ¤â€æ ¹ç›®å½• `converter.py` çš„ `reorganize_tool_messages` è¯­ä¹‰ï¼š
    - å°†æ‰€æœ‰ functionResponse æ”¶é›†èµ·æ¥
    - å°†æ‰€æœ‰ parts å¹³é“ºä¸ºâ€œæ¯ä¸ª part ç‹¬ç«‹æˆä¸€æ¡æ¶ˆæ¯â€
    - é‡åˆ° functionCall æ—¶ï¼Œè‹¥å­˜åœ¨åŒ¹é…çš„ functionResponseï¼Œåˆ™æ’å…¥åˆ°å…¶å

    æ³¨æ„ï¼šå¦‚æœå®¢æˆ·ç«¯æ ¹æœ¬æ²¡æœ‰æä¾› tool_resultï¼Œæœ¬å‡½æ•°æ— æ³•å‡­ç©ºè¡¥é½ï¼Œåªèƒ½å°½åŠ›é‡æ’ã€‚
    """
    tool_results: Dict[str, Dict[str, Any]] = {}

    for msg in contents:
        for part in msg.get("parts", []) or []:
            if isinstance(part, dict) and "functionResponse" in part:
                tool_id = (part.get("functionResponse") or {}).get("id")
                if tool_id:
                    tool_results[str(tool_id)] = part

    flattened: List[Dict[str, Any]] = []
    for msg in contents:
        role = msg.get("role")
        for part in msg.get("parts", []) or []:
            flattened.append({"role": role, "parts": [part]})

    new_contents: List[Dict[str, Any]] = []
    i = 0
    while i < len(flattened):
        msg = flattened[i]
        part = msg["parts"][0]

        if isinstance(part, dict) and "functionResponse" in part:
            i += 1
            continue

        if isinstance(part, dict) and "functionCall" in part:
            tool_id = (part.get("functionCall") or {}).get("id")
            new_contents.append({"role": "model", "parts": [part]})

            if tool_id is not None and str(tool_id) in tool_results:
                new_contents.append({"role": "user", "parts": [tool_results[str(tool_id)]]})

            i += 1
            continue

        new_contents.append(msg)
        i += 1

    return new_contents


def build_system_instruction(system: Any) -> Optional[Dict[str, Any]]:
    """
    å°† Anthropic system å­—æ®µè½¬æ¢ä¸ºä¸‹æ¸¸ systemInstructionã€‚
    """
    if not system:
        return None

    parts: List[Dict[str, Any]] = []
    if isinstance(system, str):
        if _is_non_whitespace_text(system):
            parts.append({"text": str(system)})
    elif isinstance(system, list):
        for item in system:
            if isinstance(item, dict) and item.get("type") == "text":
                text = item.get("text", "")
                if _is_non_whitespace_text(text):
                    parts.append({"text": str(text)})
    else:
        if _is_non_whitespace_text(system):
            parts.append({"text": str(system)})

    if not parts:
        return None

    return {"role": "user", "parts": parts}


def build_generation_config(payload: Dict[str, Any]) -> tuple[Dict[str, Any], bool]:
    """
    æ ¹æ® Anthropic Messages è¯·æ±‚æ„é€ ä¸‹æ¸¸ generationConfigã€‚

    é»˜è®¤å€¼ä¸ `converter.py` ä¿æŒä¸€è‡´ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šå…¼å®¹ stop_sequencesã€‚

    Returns:
        (generation_config, should_include_thinking): å…ƒç»„ï¼ŒåŒ…å«ç”Ÿæˆé…ç½®å’Œæ˜¯å¦åº”åŒ…å« thinking å—
    """
    config: Dict[str, Any] = {
        "topP": 1,
        "topK": 40,
        "candidateCount": 1,
        "stopSequences": [
            "<|user|>",
            "<|bot|>",
            "<|context_request|>",
            "<|endoftext|>",
            "<|end_of_turn|>",
        ],
    }

    temperature = payload.get("temperature", None)
    config["temperature"] = DEFAULT_TEMPERATURE if temperature is None else temperature

    top_p = payload.get("top_p", None)
    if top_p is not None:
        config["topP"] = top_p

    top_k = payload.get("top_k", None)
    if top_k is not None:
        config["topK"] = top_k

    max_tokens = payload.get("max_tokens")
    if max_tokens is not None:
        config["maxOutputTokens"] = max_tokens

    stop_sequences = payload.get("stop_sequences")
    if isinstance(stop_sequences, list) and stop_sequences:
        config["stopSequences"] = config["stopSequences"] + [str(s) for s in stop_sequences]

    # Anthropic çš„ extended thinking å¹¶éé»˜è®¤å¼€å¯ï¼›å¹¶ä¸”éƒ¨åˆ†å®¢æˆ·ç«¯ï¼ˆclaude-cli / CherryStudioï¼‰
    # å¯èƒ½ä¼šæºå¸¦ `thinking: null`ï¼Œæˆ–å¼€å¯ thinking ä½†ä¸å›æ”¾å†å² thinking blocksã€‚
    #
    # ä¸‹æ¸¸åœ¨ thinking å¯ç”¨æ—¶ä¼šæ›´ä¸¥æ ¼æ ¡éªŒå†å² assistant æ¶ˆæ¯ï¼š
    # - è‹¥å†å²ä¸­å­˜åœ¨ assistant æ¶ˆæ¯ï¼Œåˆ™"æœ€åä¸€æ¡ assistant æ¶ˆæ¯"å¿…é¡»ä»¥ thinking/redacted_thinking block å¼€å¤´
    # - max_tokens å¿…é¡»å¤§äº thinking.budget_tokens
    #
    # ä¸ºå…¼å®¹å®¢æˆ·ç«¯ï¼Œè¿™é‡Œä»…åœ¨ thinking å€¼"æ˜¾å¼ä¸”é null"æ—¶æ‰è€ƒè™‘ä¸‹å‘ï¼Œå¹¶åšå®‰å…¨å…œåº•ï¼š
    # - è‹¥æœ€åä¸€æ¡ assistant æ¶ˆæ¯ä¸ä»¥ thinking/redacted_thinking å¼€å¤´ï¼Œåˆ™ä¸ä¸‹å‘ thinkingConfigï¼ˆé¿å… 400ï¼‰
    # - è‹¥ budget >= max_tokensï¼Œåˆ™è‡ªåŠ¨ä¸‹è°ƒ budgetï¼ˆæœ€ä½é™åˆ° max_tokens-1ï¼‰ï¼Œå¦åˆ™ä¸ä¸‹å‘
    should_include_thinking = False
    if "thinking" in payload:
        thinking_value = payload.get("thinking")
        if thinking_value is not None:
            thinking_config = get_thinking_config(thinking_value)
            include_thoughts = bool(thinking_config.get("includeThoughts", False))

            last_assistant_first_block_type = None
            for msg in reversed(payload.get("messages") or []):
                if not isinstance(msg, dict):
                    continue
                if msg.get("role") != "assistant":
                    continue
                content = msg.get("content")
                if not isinstance(content, list) or not content:
                    continue
                first_block = content[0]
                if isinstance(first_block, dict):
                    last_assistant_first_block_type = first_block.get("type")
                else:
                    last_assistant_first_block_type = None
                break

            if include_thoughts and last_assistant_first_block_type not in {
                None,
                "thinking",
                "redacted_thinking",
            }:
                if _anthropic_debug_enabled():
                    log.info(
                        "[ANTHROPIC][thinking] è¯·æ±‚æ˜¾å¼å¯ç”¨ thinkingï¼Œä½†å†å² messages æœªå›æ”¾ "
                        "æ»¡è¶³çº¦æŸçš„ assistant thinking/redacted_thinking èµ·å§‹å—ï¼Œå·²è·³è¿‡ä¸‹å‘ thinkingConfigï¼ˆé¿å…ä¸‹æ¸¸ 400ï¼‰"
                    )
                return config, False

            max_tokens = payload.get("max_tokens")
            if include_thoughts and isinstance(max_tokens, int):
                budget = thinking_config.get("thinkingBudget")
                if isinstance(budget, int) and budget >= max_tokens:
                    adjusted_budget = max(0, max_tokens - 1)
                    if adjusted_budget <= 0:
                        if _anthropic_debug_enabled():
                            log.info(
                                "[ANTHROPIC][thinking] thinkingBudget>=max_tokens ä¸”æ— æ³•ä¸‹è°ƒåˆ°æ­£æ•°ï¼Œ"
                                "å·²è·³è¿‡ä¸‹å‘ thinkingConfigï¼ˆé¿å…ä¸‹æ¸¸ 400ï¼‰"
                            )
                        return config, False
                    if _anthropic_debug_enabled():
                        log.info(
                            f"[ANTHROPIC][thinking] thinkingBudget>=max_tokensï¼Œè‡ªåŠ¨ä¸‹è°ƒ budget: "
                            f"{budget} -> {adjusted_budget}ï¼ˆmax_tokens={max_tokens}ï¼‰"
                        )
                    thinking_config["thinkingBudget"] = adjusted_budget

            config["thinkingConfig"] = thinking_config
            should_include_thinking = include_thoughts
            if _anthropic_debug_enabled():
                log.info(
                    f"[ANTHROPIC][thinking] å·²ä¸‹å‘ thinkingConfig: includeThoughts="
                    f"{thinking_config.get('includeThoughts')}, thinkingBudget="
                    f"{thinking_config.get('thinkingBudget')}"
                )
        else:
            if _anthropic_debug_enabled():
                log.info("[ANTHROPIC][thinking] thinking=nullï¼Œè§†ä¸ºæœªå¯ç”¨ thinkingï¼ˆä¸ä¸‹å‘ thinkingConfigï¼‰")
    else:
        if _anthropic_debug_enabled():
            log.info("[ANTHROPIC][thinking] æœªæä¾› thinking å­—æ®µï¼ˆä¸ä¸‹å‘ thinkingConfigï¼‰")
    return config, should_include_thinking


def convert_anthropic_request_to_antigravity_components(payload: Dict[str, Any]) -> Dict[str, Any]:
    """
    å°† Anthropic Messages è¯·æ±‚è½¬æ¢ä¸ºæ„é€ ä¸‹æ¸¸è¯·æ±‚æ‰€éœ€çš„ç»„ä»¶ã€‚

    è¿”å›å­—æ®µï¼š
    - model: ä¸‹æ¸¸æ¨¡å‹å
    - contents: ä¸‹æ¸¸ contents[]
    - system_instruction: ä¸‹æ¸¸ systemInstructionï¼ˆå¯é€‰ï¼‰
    - tools: ä¸‹æ¸¸ toolsï¼ˆå¯é€‰ï¼‰
    - generation_config: ä¸‹æ¸¸ generationConfig
    """
    model = map_claude_model_to_gemini(str(payload.get("model", "")))
    messages = payload.get("messages") or []
    if not isinstance(messages, list):
        messages = []

    # ğŸ”§ ä¼˜åŒ–ï¼šæå‰æ¸…ç† thinking blocksï¼Œé¿å…ä¸‹æ¸¸æŠ¥é”™åæ‰å¤„ç†
    # æ ¸å¿ƒåŸåˆ™ï¼šåªè¦ä¸ä¼šä¸‹å‘ thinkingConfigï¼Œå°±åº”è¯¥æ¸…ç† thinking blocks
    # è¿™æ ·å¯ä»¥é¿å…æµªè´¹ tokenï¼ˆä¹‹å‰æ˜¯ä¸‹æ¸¸æŠ¥é”™åæ‰æ¸…ç†å¹¶é‡è¯•ï¼‰
    if _should_strip_thinking_blocks(payload):
        original_count = len(messages)
        messages = _strip_thinking_blocks_from_messages(messages)
        if _anthropic_debug_enabled():
            log.info(
                f"[ANTHROPIC][thinking] æ£€æµ‹åˆ° thinkingConfig ä¸ä¼šä¸‹å‘ï¼Œå·²æå‰æ¸…ç†å†å²æ¶ˆæ¯ä¸­çš„ thinking blocks "
                f"(messages={original_count})"
            )

    # å…ˆæ„å»º generation_config ä»¥ç¡®å®šæ˜¯å¦åº”åŒ…å« thinking
    generation_config, should_include_thinking = build_generation_config(payload)

    # æ ¹æ® thinking é…ç½®è½¬æ¢æ¶ˆæ¯
    contents = convert_messages_to_contents(messages, include_thinking=should_include_thinking)
    contents = reorganize_tool_messages(contents)
    system_instruction = build_system_instruction(payload.get("system"))
    tools = convert_tools(payload.get("tools"))

    return {
        "model": model,
        "contents": contents,
        "system_instruction": system_instruction,
        "tools": tools,
        "generation_config": generation_config,
    }
